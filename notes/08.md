#### 文本改写，从使用提示语开始

Notion AI: 可以在已经写好的文章里面选取一段内容，你可以让 AI 帮你修改。

OpenAI 的 GPT 的系列模型是一个生成式的模型，也就是它的用法是你给它一段文字，然后它补全后面的文字。按理来说，是无法让它修改一段文字的。

不过，可以通过一段提示语来解决这个问题。我们可以通过上一节课的 ChatGPT 的模型来实现了这个功能

使用 ChatGPT 的接口，是因为它的价格比较低廉。而我们使用的参数也有以下几个调整。

1. n=3 这个参数，也就是让 AI 给我们返回 3 个答案供我们选择。
2. 其次是我们引入了两个参数 presence_penalty=0 以及 frequency_penalty=2。它们和 temperature 参数类似，都是来控制你输出的内容的。
   a. presence_penalty，顾名思义就是如果一个 Token 在前面的内容已经出现过了，那么在后面生成的时候给它的概率一定的惩罚。
   b. frequency_penalty，指的是对于重复出现的 Token 进行概率惩罚。

#### 通过 logit_bias 参数精确控制内容

比如我们在上面生成的文字中，不允许出现灾害两个字。我们可以这么做：

1. 我们通过之前使用过的 Tiktoken 库，把我们不希望出现的“灾害”这个词儿，找到它对应的 Token，然后给它们都赋了一个 -100 的 bias。
2. 然后把整个的 bias_map 作为参数，传给了 Completion 的 logit_bias 参数。

对于 logit_bias 参数里面的取值范围，是在 -100 到 100 之间。不过，一般情况下，设置在 1 到 -1 之间就足够了。

#### 使用英文来减少 Token 的使用

如果你在生产环境中使用 OpenAI 的接口，最好还是使用英文的提示语，最多在输出结果的时候，告诉它 “generate Chinese” 之类的，可以极大地节约成本。

#### 看看 OpenAI 给了我们哪些模型

因为目前 OpenAI 的产品更新非常快，所以很可能会出现一个问题，我告诉你应该使用某个模型，但是这个模型已经不是效果最好或者最新的了。所以，最好的办法，还是通过它提供的接口看看它到底有哪些模型。

```
import pandas as pd
# list all open ai models
engines = openai.Engine.list()
pd = pd.DataFrame(openai.Engine.list()['data'])
display(pd[['id', 'owner']])
```

输出结果：

```

  id  owner
0  babbage  openai
1  davinci  openai
2  babbage-code-search-code  openai-dev
3  text-similarity-babbage-001  openai-dev
4  text-davinci-001  openai
……
14  text-embedding-ada-002  openai-internal
……
30  gpt-3.5-turbo-0301  openai
……
41  gpt-4  openai
42  text-search-davinci-doc-001  openai-dev
43  gpt-4-0314  openai
……
47  text-similarity-davinci-001  openai-dev
48  text-davinci-002  openai
49  davinci-similarity  openai-dev
```

不过，里面的很多模型都已经老旧了，实际上主要用的模型就是这几类。

1. GPT-4 家族的模型，包括 gpt-4 和 gpt-4-0314。使用的方式和 ChatGPT 的模型一样，其中带日期的模型表示是一个模型快照。
2. GPT-3.5 家族的模型，包括 ChatGPT 所使用的 gpt-3.5-turbo 或者 gpt-3.5-turbo-0301，以及 text-davinci-003 和 text-davinci-002 这两个模型。
3. 剩下的，则是 Ada、Babbage、Curie 以及 Davinci 这四个基础模型。只适合用于下达单轮的指令，不适合考虑复杂的上下文和进行逻辑推理。如果要微调一个属于自己的模型，也需要基于这四个基础模型。
4. 最后则是 text-embedding-ada-002、text-similarity-ada-001 这些专门用途模型。一般来说，我们通过这个模型来获取 Embedding，再用在其他的机器学习模型的训练，或者语义相似度的比较上。

> 所有模型的名字都来自科学史上的名人。
> Ada 来自人类史上第一位程序员 Ada，她也是著名诗人拜伦的女儿。
> Babadge 则是设计了分析机的巴贝奇，巴贝奇分析机也被认为是现代计算机的前身。
> Curie 则是指居里夫人
> Davinci 是指达芬奇。

#### 插入内容，GPT 也可以像 BERT

我们前面介绍的时候说过，text-davinci-003 这个模型有个特殊的功能，就是“插入文本”（Inserting Text）。某种意义上来说，你也可以通过这个功能来做文本改写。

```
prefix = """在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。
在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\n"""
# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。
suffix = """\n面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。
这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。
只有这样，我们才能真正地实现自己的潜力并取得成功。"""

def insert_text(prefix, suffix):
    response = openai.Completion.create(
        model="text-davinci-003",
        prompt=prefix,
        suffix=suffix,
        max_tokens=1024,
        )
    return response

response = insert_text(prefix, suffix)
print(response["choices"][0]["text"])
```

输出结果：

```
另一些是内部因素，例如事业难以发展、无法解决的个人和家庭矛盾等。
```

这个接口的使用，和普通的 Completion 接口基本一致，只有一个区别就是除了前缀的 prompt 参数之外，还需要一个后缀的 suffix 参数。

如果把上边的内容改一改，比如去掉 Suffix 一开始的换行符号，插入的文本内容有些就会在我们的预期之外。

```
prefix = """在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。
在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\n"""
# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。
suffix = """面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。
这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。
只有这样，我们才能真正地实现自己的潜力并取得成功。"""

response = insert_text(prefix, suffix)
print(response["choices"][0]["text"])
```

输出结果：

```
例如，因应全球变暖，政府和人民在做出更加清晰的计划时就面临着巨大的压力，以减少大气污染和减少碳排放。
更重要的是，每个人必须为自己所做的付出努力，以防止这些外部环境变化的不利影响。
此外，也存在一些由内部因素引起的挑战和困难，比如心理问题，贫穷和学习困难。
例如，一些人因为焦虑或抑郁症而无法集中精力，他们的学习能力受到了影响，从而影响了他们的学业成绩。
再者，贫穷也是另一个棘手的话题，它影响了一个人的生活质量，从而阻碍了他们发展个人潜能的能力。
因此，
```

可以看到，AI 一下子啰嗦了很多，并且最后一句不是个完整的句子，而是下句话开头的内容。在使用这个 INSERT 接口的时候，考虑好文本之间需要使用什么样的分隔符，是非常重要的。

#### 不要乱问乱说，做个“正直”的 AI

Moderate--OpenAI 对于自然语言处理提供的最后一个接口，可以让你对输入以及返回的内容做个检查。如果出现了这样的内容，你也可以屏蔽这些用户的访问，也可以人工审核一下用户的问题。

```
threaten = "你不听我的我就拿刀砍死你"

def moderation(text):
    response = openai.Moderation.create(
        input=text
    )
    output = response["results"][0]
    return output
print(moderation(threaten))
```

输出结果：

```
{
  "categories": {
    "hate": false,
    "hate/threatening": false,
    "self-harm": false,
    "sexual": false,
    "sexual/minors": false,
    "violence": true,
    "violence/graphic": false
  },
  "category_scores": {
    "hate": 0.030033664777874947,
    "hate/threatening": 0.0002820899826474488,
    "self-harm": 0.004850226454436779,
    "sexual": 2.2907377569936216e-05,
    "sexual/minors": 6.477687275463495e-09,
    "violence": 0.9996402263641357,
    "violence/graphic": 4.35576839663554e-05
  },
  "flagged": true
}
```

可以看到，moderate 的接口返回的是一个 JSON，里面包含是否应该对输入的内容进行标记的 flag 字段，也包括具体是什么类型的问题的 categories 字段，以及对应每个 categories 的分数的 category_scores 字段。我们举的这个例子就被标记成了 violence，也就是暴力。

因为这个接口是免费的，所以你对所有的内容无论是输入还是输出，都可以去调用一下这个接口。
