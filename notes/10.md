#### 大型语言模型的不足之处

在中文常识和具有时效性的问题，GPT-3 的回答就会很扯。

之所以会出现这样的情况，和大模型的原理以及它使用训练的数据集是有关的。大语言的模型的原理，就是利用训练样本里出现的文字的前后关系，通过前面的文本对接下来出现的文本进行概率预测。如果类似前后文本出现得越多，那么这个概率就会收敛到少数正确答案上，回答就准确；如果这样的文本很少，那么训练过程就会有一定的随机性，答案就容易似是似非。

对于常识类的问答，可以多找一些高质量的中文语料训练一个新模型。或者，对于想让 AI 能够回答出来的问题，找一些数据。然后利用 OpenAI 提供的微调（Fine-tune）接口，在原来的基础上训练一个新模型出来。

这样做是可以的，就是成本有点高。而且对于实时性的信息，就很难这么做了。

#### Bing 的解法——先搜索，后提示

Bing 加了 ChatGPT 的问答功能，似乎效果还不错。

1. 我们先通过搜索的方式，找到和询问的问题最相关的语料。这个搜索过程中，我们既可以用传统的基于关键词搜索的技术，也可以用第 9 讲我们刚刚介绍过的使用 Embedding 的相似度进行语义搜索的技术。
2. 然后，我们将和问题语义最接近的前几条内容，作为提示语的一部分给到 AI。然后请 AI 参考这些内容，再来回答这个问题。

举了例子。当我们把《藤野先生》里的两个段落给到 AI，然后请 AI 根据这两个段落，回答原来那个问题，就会得到正确的答案，你也可以去看一看。

这也是利用大语言模型的一个常见模式：

1. 第一种，是海量的语料中，本身已经包含了的知识信息。
2. 第二种，是根据你输入的内容，理解和推理的能力。这个能力，不需要训练语料里有一样的内容。而是大语言模型本身有“思维能力”，能够进行阅读理解。这个知识不是模型本身提供的，是我们找出来的，临时提供给模型的。

#### 通过 llama_index 封装“第二大脑”

先搜索，后提示。我们叫做 AI 的“第二大脑”模式。因为这个方法，需要提前把你希望 AI 能够回答的知识，建立一个外部的索引，这个索引就好像 AI 的“第二个大脑”。每次向 AI 提问的时候，它都会先去查询一下这个第二大脑里面的资料，找到相关资料之后，再通过自己的思维能力来回答问题。

这个模式就像很多论文、读书回答问题的应用，都是通过这种模式实现的。

这个模式太过常用了，所有有人为他写了一个开源 Python 包，叫做 llama-index。

#### 通过 llama_index 对于文章进行小结

还有 llama_index 这样“第二大脑”的 Python 库的常见应用场景，就是生成文章摘要。

前面通过文本聚类，可以通过合适的提示语（Prompt）做到。但是如果是一篇论文、甚至是一本书，每次最多只能支持 4096 个 Token 的 API 就不太够用了。

要解决这个问题也并不困难，我们只要进行分段小结，再对总结出来的内容再做一次小结就可以了。可以对文档或是论文生成一个树状的索引，在每个树里的节点就是树下的内容的摘要。最后，在整棵树的根节点，得到的就是整篇文章或者整本书的总结了。

接下来的代码很简单，我们选用了 GPTListIndex 这个 llama-index 里最简单的索引结构。不过我们针对自身需求做了两点优化。

1. 首先，在索引里面，我们指定了一个 LLMPredictor，让我们向 OpenAI 发起请求的时候，都使用 ChatGPT 的模型。因为这个模型比较快，也比较便宜。
2. 其次，我们定义了使用 SpacyTextSplitter 来进行中文文本的分割。llama-index 默认的设置对于中文的支持和效果都不太好。不过好在它可以让你自定义使用的文本分割方式。

GPTListIndex 在构建索引的时候，并不会创建 Embedding，所以索引创建的时候很快，也不消耗 Token 数量。它只是根据你设置的索引结构和分割方式，建立了一个 List 的索引。

接着，我们就可以让 AI 帮我们去小结这篇文章了。

1. 提示语本身很重要，所以我们还是强调了文章内容是鲁迅先生以“我”这个第一人称写的。
2. 因为我们想要的是按照树状结构进行文章的小结，所以我们设定了一个参数，叫做 response_mode = “tree_summarize”。这个参数，就会按照上面我们所说的树状结构把整个文章总结出来。

```
response = list_index.query("下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:", response_mode="tree_summarize")
print(response)
```

#### 引入多模态，让 llamd-index 能够识别小票

llama_index 不光能索引文本，很多书里面还有图片、插画这样的信息。llama_index 一样可以索引起来，供你查询，这也就是所谓的多模态能力。

当然，这个能力其实是通过一些多模态的模型，把文本和图片能够联系到一起做到的。

这里我们就来看一个 llama_index 官方样例库里面给到的例子，也就是把吃饭的小票都拍下来。然后询问哪天吃了什么，花了多少钱。

```
from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex
from llama_index.readers.file.base import DEFAULT_FILE_EXTRACTOR, ImageParser
from llama_index.response.notebook_utils import display_response, display_image
from llama_index.indices.query.query_transform.base import ImageOutputQueryTransform

image_parser = ImageParser(keep_image=True, parse_text=True)
file_extractor = DEFAULT_FILE_EXTRACTOR
file_extractor.update(
{
    ".jpg": image_parser,
    ".png": image_parser,
    ".jpeg": image_parser,
})

# NOTE: we add filename as metadata for all documents
filename_fn = lambda filename: {'file_name': filename}

receipt_reader = SimpleDirectoryReader(
    input_dir='./data/receipts',
    file_extractor=file_extractor,
    file_metadata=filename_fn,
)
receipt_documents = receipt_reader.load_data()
```

要能够索引图片，我们引入了 ImageParser 这个类，这个类背后，其实是一个基于 OCR 扫描的模型 [Donut](https://huggingface.co/naver-clova-ix/donut-base-finetuned-cord-v2)。它通过一个视觉的 Encoder 和一个文本的 Decoder，这样任何一个图片能够变成一个一段文本，然后我们再通过 OpenAI 的 Embedding 把这段文本变成了一个向量。

我们仍然只需要使用简单的 SimpleDirectoryReader，我们通过指定 FileExtractor，会把对应的图片通过 ImageParser 解析成为文本，并最终成为向量来用于检索。

然后，我们仍然只需要向我们的索引用自然语言提问，就能找到对应的图片了。

在提问的时候，我们专门制定了一个 ImageOutputQueryTransform，主要是为了在输出结果的时候，能够在图片外加上 的标签方便在 Notebook 里面显示。

```
receipts_index = GPTVectorStoreIndex.from_documents(receipt_documents)
receipts_response = receipts_index.query(
    'When was the last time I went to McDonald\'s and how much did I spend. \
    Also show me the receipt from my visit.',
    query_transform=ImageOutputQueryTransform(width=400)
)

display_response(receipts_response)
```

输出结果：

```
INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1004 tokens
INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 30 tokens

Final Response: The last time you went to McDonald's was on 03/10/2018 at 07:39:12 PM and you spent $26.15. Here is the receipt from your visit:
```

可以看到，答案中不仅显示出了对应的图片，也给出了正确的答案，这也要归功于 OpenAI 对于任意文本强大的处理能力。

我们可以单独解析一下图片，看看对应的文本内容是什么：

```

<s_menu><s_nm> Story</s_nm><s_num> 16725 Stony Platin Rd</s_nm><s_num> Store#:</s_nm><s_num> 3659</s_num><s_price> 700-418-8362</s_price><sep/><s_nm> Welcome to all day breakfast dormist O Md Donald's</s_nm><s_num> 192</s_num><s_price> 192</s_price><sep/><s_nm> QTY ITEM</s_nm><s_num> OTAL</s_num><s_unitprice> 03/10/2018</s_unitprice><s_cnt> 1</s_cnt><s_price> 07:39:12 PM</s_price><sep/><s_nm> Delivery</s_nm><s_cnt> 1</s_cnt><s_price> 0.00</s_price><sep/><s_nm> 10 McNuggets EVM</s_nm><s_cnt> 1</s_cnt><s_price> 10.29</s_price><sep/><s_nm> Barbeque Sauce</s_nm><s_cnt> 1</s_cnt><s_price> 1</s_price><sep/><s_nm> Barbeque Sauce</s_nm><s_num> 1</s_cnt><s_price> 0.40</s_price><sep/><s_nm> L Coke</s_nm><s_cnt> 1</s_cnt><s_price> 0.40</s_price><sep/><s_nm> M French Fries</s_nm><s_cnt> 1</s_cnt><s_price> 3.99</s_price><sep/><s_nm> HM GrChS S-Fry Yog</s_nm><s_cnt> 1</s_cnt><sep/><s_nm> Smoonya</s_nm><s_cnt> 1</s_cnt><sep/><s_nm> HM Apple Juice</s_nm><s_cnt> 1</s_cnt><s_price> 2.89</s_price><sep/><s_nm> Cookies</s_nm><s_cnt> 6</s_cnt><s_price> 2.89</s_price><sep/><s_nm> Choc Chip Cookie</s_nm><s_cnt> 6</s_cnt><s_price> 1.19</s_price><sep/><s_nm> Baked Apple Pie</s_nm><s_cnt> 1</s_cnt><s_price> 3.29</s_price><sep/><s_nm> French Fries</s_nm><s_cnt> 1</s_cnt><s_price> 2.99</s_price><sep/><s_nm> Iced Tea</s_nm><s_cnt> 1</s_cnt><s_price> 2.99</s_price></s_menu><s_sub_total><s_subtotal_price> 25.04</s_subtotal_price><s_tax_price> 1.11</s_tax_price></s_sub_total><s_total><s_total_price> 26.15</s_total_price><s_changeprice> 0.00</s_changeprice><s_creditcardprice> 26.15</s_creditcardprice></s_total>
```

可以看到，对应的就是 OCR 后的文本结果，里面的确有对应我们去的店铺的名字和时间，以及消费的金额。

围绕 OpenAI 以及整个大语言模型的生态还在快速发展中，所以 llama-index 这个库也在快速迭代。对于开源项目，它已经有一个很不错的生态，特别是提供了大量的 DataConnector，既包括 PDF、ePub 这样的电子书格式，也包括 YouTube、Notion、MongoDB 这样外部的数据源、API 接入的数据，或者是本地数据库的数据。你可以在 [llamahub.ai](https://llamahub.ai/) 看到社区开发出来的读取各种不同数据源格式的 DataConnector。
